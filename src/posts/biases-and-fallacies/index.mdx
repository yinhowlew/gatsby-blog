---
title: Biases and Fallacies
description: are you good at reading people?
featuredImage: NotAvgJoe-group.webp
tags:
 - RealTalk
 - Business 
date: 2022-01-24
---
<p style={{fontSize: "0.7em", fontStyle: "italic"}}>NFTs of a crypto-story comic strip I minted from !=Avg(Joe) https://notavgjoe.com/</p>


In the Western world, the ideal person is rational — one who is able to reason and come to sound conclusions.

In fact, the entire Western philosophy and civilization is built on Socrates's and Plato's idea that we have a perfectly rational mind which, through deliberate intellectual and philosophical enquiries, would give us access to perfect knowledge of what is good and live virtuously.

Similarly in Economics theory, we are all rational agents who responds to incentives, weighs the trade-off of different choices, and make the right decision that maximizes our utility. 

--- 

As much as we think we are completely rational and capable of making good decisions, in reality, we are far from perfect.

On a personal level, we are prone to cognitive biases of all kinds that cause us to make bad decisions — hiring the wrong person, unwise investments, irrational product decisions, etc.

Collectively, we are subject to manipulation, fake news, conspiracy theories, FUD (fear, uncertainty, and doubt), and post-truth rhetorics evident in politics and stock markets.

Below are some cognitive biases and fallacies that I often find in myself and those around me — and ways we can avoid and use these mental pitfalls and traps to our advantage.

Table of Content:

1. <a href="#judging-others">Fallacy in how we evaluate and trust others</a>
2. <a href="#confirmation-bias">Confirmation Bias</a>
3. <a href="#self-serving">Self-Serving Bias</a>
4. <a href="#anchoring-bias">Anchoring Bias</a>
5. <a href="#other-biases">Other Biases</a>
6. <a href="#why-and-how">Why do we have these cognitive biases and how to overcome them</a>

---

<h2 id="judging-others">1 - Fallacy in how we evaluate and trust others</h2>

> "If we spend some time in person, and I look him in the eyes, I will know what kind of man he is"

Have you ever wondered if you are a good judge of a person's character? If you are good at reading if someone is sincere or bullshitting?

I used to think I am. But in retrospect, I have made plenty of mistakes judging / evaluating someone: 

- hiring a candidate who didn't seem great on paper and later turned out to be a disaster simply because I overly trusted my read after a good 30-minute chat 
- trusting poker acquaintances with money who later went MIA
- rushing into a business partnership without fully evaluating my partners and the opportunity.


In "Talking to Strangers", Malcolm Gladwell examines a few cognitive behaviors that we have when dealing with others.

One of them is **Default to Truth** — we tend to take on face value the things people tell us. In the book, he uses the example of Neville Chamberlain, UK Prime Minister during the years leading to WWII. When the entire Europe started getting uneasy about Germany's actions, Chamberlain went to meet Hitler to try to figure out Hitler's ambitions and motives. He felt he was a good judge of someone's character especially when meeting them in person. After Hitler gave Chamberlain his assurance and a double handshake reserved for trusted friends, Chamberlain walked away from the meeting feeling assured that Hitler had no intention on the larger Europe continent. We all know how that went.

Another psychological pitfall that clouds our judgment of a person is our tendency to have an  **illusion of asymmetrical insight** — where we perceive our knowledge of others to surpass others' knowledge of us, thinking that we are more nuanced and complex, while perceiving others as more easy to get insights on.

Together, these two behaviors give us a sometimes **unwarranted confidence and trust in the information gather from a personal interaction**, believing them to be uniquely valuable and transparent.

Some of us probably think we are better than most in reading people — most poker players think they are good at reading their opponents — but a better explanation of why we might hold such belief is confirmation bias and selective memory, which we will talk about later.

In fact, <a href="https://gap.hks.harvard.edu/orchestrating-impartiality-impact-%E2%80%9Cblind%E2%80%9D-auditions-female-musicians">studies</a>
show that orchestras hire better when the auditions are "blind"  — without face-to-face interaction — leading to more diverse and better-performing musicians.

In another example, when deciding which suspects should be released on bail and who should remain in jail, judges with years of experience who relies on in-person evaluation <a href="https://cs.stanford.edu/people/jure/pubs/bail-qje17.pdf">performs worse than computer algorithm</a>. 


<h2 id="confirmation-bias">2 - Confirmation Bias</h2>

> "our market research shows people really like what we are building"

Confirmation Bias is a bad habit of seeking and remembering evidence that confirms a belief, and avoiding information that might contradict said belief. When we start with a set of preconceptions, we tend to focus on and over-emphasize information that further confirms our preconceptions.

For instance, if you believe that vaccine is harmful to the human body, you might start zeroing in on information sources that are anti-vaccination and disregarding contradictory information from other scientists, further entrenching your belief.

This is an especially prominent bias in businesses and startups. In modern startup playbook, we start with certain hypothesis about the market or customer preference, and conduct market research and user interview to confirm our hypothesis. But often, our approach is tainted with confirmation bias; **we pay more attention to information that fits our narrative and further commit to the project, despite plenty of signs pointing otherwise**.

A wise friend of mine, after listening to my passionate pitch of an idea armed with evidence from user research, once asked:
> "what is something that, if true, will break apart your assumptions?"

Karl Popper, a influential philosopher of Science, insists that the dividing line between science and pseudoscience is whether advocates of a hypothesis **deliberately search for evidence that could falsify it** and accept the hypothesis only if it survives.


<h2 id="self-serving">3 - Self-Serving Bias</h2>

> "I worked hard for it. I made it happen."

We are the protagonists and heroes in our own stories. Often, we tend to attribute success to our own efforts and abilities, but ascribe failure to external and situational factors.

Self-serving bias serves an incredibly powerful heuristic in protecting our self-esteem and making us feel good about ourselves. But it can also sometimes lead to dishonest and unrealistic attributions where we fail to examine and learn from our own shortcomings. For instance, thinking we got a job because of our merits, or believing our failure is due to bad luck.

In poker, you can often see bad players blaming their loss to luck, and failing to pinpoint and learn from things they could have done better.


<h2 id="anchoring-bias">4 - Anchoring Bias</h2>

> "The iPhone is $1,199. This $29 Lightning Cable is a steal."

Our decisions are heavily influenced by our points of reference. The information we gather first will often serve as a anchor point and significantly influence how we evaluate subsequent information we come across.

For instance, when you are negotiating to a client, the initial price you set for your service is $10,000. When you finally made a concession and offered a deal for $7,500, it will come across as an attractive deal to your client compared to the $10,000 anchor — even if $7,500 is still a very comfortable fee for you.

When you interview for a new company and get to salary negotiation, conventional wisdom is that you should not be the first person to name the expected salary. But studies show that being the first one to put a number down on the table might be the best way to go. **Whoever makes the first offer has the edge of setting the anchor salary that establishes a range of acceptable counteroffers** in the subsequent rounds of negotiation. Just make sure you have done your research and set an anchor number on the upper range for your role.

As a consumer, when you come across an attractive deal that discounts a $1000 product to S200, you need to be mindful if the perceived attractiveness is influenced by the $1000 anchor.


<h2 id="other-biases">5 - Other Biases</h2>

### Recency Bias

> Bitcoin price has always managed to survive downswings and pushed to new heights. This time is no different.

We overweigh recent events and information that are freshest in our memory. In 2021, after a 10-year bull market (U.S. equities), many new investors expect the market to continue going up in value indefinitely, ignoring the risks and fundamentals involved in investing in this asset class.

### Rosy Retrospection

> good ol' days

I often look at past events or periods of my life with rose-tinted glasses. Perhaps it is an evolutionary heuristic we have developed to selectively blur out the negative, traumatic, non-self-serving events that might otherwise make us feel less optimistic and less anxious.

Feeling at peace about the past is undoubtedly favorable, but we shouldn't let our unrealistic idea of the past clouds what we think of the present and the future.


### Dunning–Kruger Effect 

> you don't know what you don't know

Dunning–Kruger effect is the tendency of people with low ability in a particular domain to overestimate their ability. 

Simply put, when we are bad at something, we won't have an accurate level of self-awareness to objectively evaluate our own competence. In fact, a study shows 42% of software engineers rated their professional abilities as being among the top 5% of their peers.

Confidence is not necessarily a bad thing. But if we want to be honest with ourselves and know where we stand, we should be careful of the pitfall of Dunning-Kruger effect, and actively seek feedbacks from other peers.


### Sunk Cost Fallacy

> "we bought TSLA at $700, we can't sell it at $500 now"

This fallacy is our tendency to follow through something if we have already invested resources in it — even if the endeavor will be a losing proposition for us.

For example, when R.J. Reynolds Tobacco spent years and resources developing an experimental smokeless cigaratte back in 1980s, the executives were clouded by sunk cost fallacy and continued to pour in more money into the project instead of cutting their loss, despite 95% of users in test markets hated the taste. The project was finally shut down after its national-wide launch tanked.

Sometimes, after working on a project for a few years, we might feel too invested in it that we fail to evaluate if it is still the best use of our future time and resources, and we end up **throwing good money after bad**. 


<h2 id="why-and-how">6 - Why do we have these cognitive biases and how to overcome them</h2>

Some of our cognitive biases are developed as social heuristics — e.g. trusting other people by default makes it much **more efficient and less energy-intensive** in our daily social interaction with others. Taking other's words for it, instead of being doubtful by default, enables a smoother interaction and transaction in a society.

Other times, our cognitive biases arise as a **defense mechanism** — taking a short-cut when being exposed to overwhelming amount of information that we can't process in details and nuances. The explosion in knowledge and technology in the past few hundred years far surpasses what our brain can evolve and handle, since our brain is still mostly unchanged from the hunter-gather days, and our social / cultural conventions are still largely based on our village-agricultural days. 

Our cognitive biases and short-cut in thinking serve as tools and practical trade-offs that allow us to carry on our daily lives and feel good about ourselves while stopping us from getting overwhelmed.

Simply put, it is too expensive and overwhelming for our brain and energy to always be engaging in critical thinking and challenging the assumptions and veracity of every piece of information we are exposed to.

---

In "Thinking Fast and Slow", Daniel Kahneman theorizes we have two systems and modes of thinking, and recommends tapping more into the slower, less automatic system that will better help check our biases and emotions.

It might be tiring to deliberate on every decision and examine every piece of information we come across. But for major and important matters, we can put in **systems that safeguards against our mental pitfalls**. 

When hiring for an important role, instead of over-relying on in-person interview, we can do additional vetting, call up references, conduct relevant and fair task/assignment-based interview that can better gauge his/her performance, and perhaps have multiple interviewers with different profiles to cancel out any bias.

On any personal decision that involves a significant sum of money, take time on it, seek advice from trusted friends, understand the risk and trade-off before writing your cheque.


## Reference

- "Thinking Fast and Slow" by Daniel Kahneman

- "Talking to Strangers" by Malcolm Gladwell book

- "Rationality" by Steven Pinker